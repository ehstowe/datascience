{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PredictingFire.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOgb5z6hRw2+CGSd/LnB05s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehstowe/datascience/blob/main/PredictingFire.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mihT3BbhVw5"
      },
      "source": [
        "#Final Project: Predicting Fire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPp0ZhnQ81ha"
      },
      "source": [
        "Emma Stowe  \n",
        "DSC 305a SP20  \n",
        "Final Project: Predicting Fire\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyBRzrnf8_Be"
      },
      "source": [
        "#Summary\n",
        "This project is an analysis of data collected by the City of Detroit regarding fires in 2015. The data includes the time and date of almost 20,000 emergency calls, the geographic coordinates of the location the call was made from, the type of structure the call is reporting from (single family home, apartment building, business, school, etc), the time and date of dispatch, time and date of the crew's arrival to the scene, time and date the scene was cleared, and any injuries  or fatalities reported. The part of the dataset I chose to focus on was the recording of false alarms. \n",
        "\n",
        "I wanted to investigate this question: Can we predict false alarms when they are made? False alarms cost fire departments - and therefore, taxpayers - billions of dollars each year. With a perfect model, much of this money could be better spent. Even an imperfect model could help fire departments know how to best allocate their resources, sending less experienced crews or less equipped trucks to the scene. Finally, if the results were generalizable, this could greatly help fire stations in more rural areas where they may only have one or two firetrucks for a large service area. \n",
        "\n",
        "I tried many models in an attempt to find one to classify a call as a False Alarm or Not a False Alarm. I was not able to find a perfect one, but some are better than others. My best models are a Random Forest Classifier and a Gradient Boosting Classifier, both with tuned hyperparameters. \n",
        "\n",
        "A major challenge of this problem is that the data is highly skewed. There are significantly more non-false alarms (I considered these the negative class) than false alarms (positive class). That means that models that classify all calls as non-false alarms have relatively high accuracy. This is the idea that fire departments currently work with, so I wanted to do better. Still, I recognize that a false positive (predicting a call was a false alarm when it was not) has an extreme cost in this case, much more than a false negative (predicting a call was not a false alarm when it was). So, I created a new benchmark, combining precision and recall like F1 score does, but giving more weight to precision because a higher precision means fewer false positives. My benchmark weights precision at .75 and recall at .25. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPujvAq483JG"
      },
      "source": [
        "The following functions are included in the \"General Functions\" code cell: \n",
        "</ul>\n",
        "<li>Binarizing a column: takes in a column name and a dataframe and adds all necessary columns to the dataframe</li>\n",
        "<li>Evaluate binary: takes in the true values and the predicted values and displays a confusion matrix and prints the accuracy, precision, recall, F1, and benchmark scores, as well as area under the ROC curve.</li>\n",
        "<li>Run classifier: takes a classifier and training and testing data and runs that classifier on the data, then appends the values for accuracy, precision, recall, F1, benchmark, and area under the ROC curve onto their respective arrays.</li>\n",
        "<li>Show max stats: takes training and testing data, empty arrays accuracy, precision, recall, F1, and benchmark, area under the ROC curve, and a list of classifiers and runs each classifier in the list through the 'run classifier' function, outputs the classifier with the highest value in each array. </li>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsO8mnSbUJIZ",
        "outputId": "79d4ff72-2eaf-40c9-d649-d2f48d611429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#@title Import Statements\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn import datasets, svm, metrics\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from sklearn.utils import resample \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from numpy import nan\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier as ABC\n",
        "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.neighbors import NearestCentroid as NC\n",
        "from sklearn.multiclass import OneVsRestClassifier as OVRC"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqW2Q1fektZp"
      },
      "source": [
        "#@title General Functions\n",
        "def go_through_set(colName, df):\n",
        "    for x in set(df[colName]):\n",
        "        x = str(x)\n",
        "        create_new_col(x, colName, x, df)\n",
        "def create_new_col(newColName, oldColName, whatIs1, df):\n",
        "    df[newColName]=df[oldColName].apply(lambda x: 1 if(x==whatIs1) else 0)\n",
        "\n",
        "def evaluate_binary(y_true, y_pred):\n",
        "  data = confusion_matrix(y_true, y_pred)\n",
        "  df_cm = pd.DataFrame(data, columns=np.unique(y_true), index = np.unique(y_true))\n",
        "  df_cm.index.name = 'Actual'\n",
        "  df_cm.columns.name = 'Predicted'\n",
        "  plt.figure(figsize = (6,2))\n",
        "  sns.set(font_scale=1)#for label size\n",
        "  sns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16}, fmt='g')\n",
        "  print(\"---------------------------------------------------\")\n",
        "  accuracy_clf=float(str(metrics.accuracy_score(y_test, y_pred))[0:6])\n",
        "  precision_clf=float(str(metrics.precision_score(y_test, y_pred, pos_label=1))[0:6])\n",
        "  recall_clf=float(str(metrics.recall_score(y_test, y_pred))[0:6])\n",
        "  f1_clf=float(str(metrics.f1_score(y_test, y_pred))[0:6])\n",
        "  benchmark_clf=float(str((precision_clf*3+recall_clf)/4)[0:6])\n",
        "  auc_clf=float(str(metrics.roc_auc_score(y_true, y_pred, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None))[0:6])\n",
        "  print('Accuracy: ',accuracy_clf)\n",
        "  print('Precision: ',precision_clf)\n",
        "  print('Recall: ',recall_clf)\n",
        "  print('F1: ', f1_clf)\n",
        "  print('Benchmark:', benchmark_clf)\n",
        "  print('AUC:',auc_clf)\n",
        "  print(\"---------------------------------------------------\")\n",
        "\n",
        "\n",
        "def run_classifier(clf, X_train0, X_test0, y_train0, y_test0):\n",
        "  model=clf()\n",
        "  model.fit(X_train0, y_train0)\n",
        "  y_pred=model.predict(X_test0)\n",
        "  accuracy_clf=float(str(metrics.accuracy_score(y_test0, y_pred))[0:6])\n",
        "  precision_clf=float(str(metrics.precision_score(y_test0, y_pred, pos_label=1))[0:6])\n",
        "  recall_clf=float(str(metrics.recall_score(y_test0, y_pred))[0:6])\n",
        "  f1_clf=float(str(metrics.f1_score(y_test0, y_pred))[0:6])\n",
        "  benchmark_clf=float(str((precision_clf*3+recall_clf)/4)[0:6])\n",
        "  auc_clf=float(str(metrics.roc_auc_score(y_test0, y_pred, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None))[0:6])\n",
        "  model_name = type(model).__name__\n",
        "  accuracy.append(accuracy_clf)\n",
        "  precision.append(precision_clf)\n",
        "  recall.append(recall_clf)\n",
        "  f1.append(f1_clf)  \n",
        "  benchmark.append(benchmark_clf)\n",
        "  auc.append(auc_clf)\n",
        "\n",
        "def show_max_stats(X_train0, X_test0, y_train0, y_test0, classifiers, accuracy, precision, recall, f1, benchmark, auc):\n",
        "  stats = [accuracy, precision, recall, f1, benchmark, auc]\n",
        "  stats_strings=['accuracy', 'precision', 'recall', 'f1', 'benchmark', 'auc']\n",
        "  classifier_strings=['LogisticRegression', 'RandomForestClassifier', 'GaussianNB', 'BernoulliNB', 'DecisionTreeClassifier', 'BaggingClassifier', 'ExtraTreesClassifier', 'svm.SVC', 'Perceptron', 'LDA', 'MLPClassifier', 'ABC', 'GBC', 'Perceptron']\n",
        "  for clf in classifiers:\n",
        "    run_classifier(clf, X_train0, X_test0, y_train0, y_test0) \n",
        "\n",
        "  print('----------------------------------------------------------')\n",
        "\n",
        "  for measure in range(6):\n",
        "    counter=0\n",
        "    i_max=0\n",
        "    i_max=stats[measure][0]\n",
        "    i_max_index=0\n",
        "    for x in stats[measure]:\n",
        "      if x>i_max:\n",
        "        i_max=x\n",
        "        i_max_index=counter\n",
        "        model=classifier_strings[i_max_index]\n",
        "      counter=counter+1\n",
        "      \n",
        "    print('max '+stats_strings[measure]+'='+model+' at '+str(i_max))\n",
        "\n",
        "  print('----------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN4njI_9A8dB"
      },
      "source": [
        "#Data Exploration and Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BDlbzl8PdnJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZZ1RFzcHtXj",
        "cellView": "form",
        "outputId": "26588c47-b998-47e8-bd3c-1ca74e80df18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        }
      },
      "source": [
        "#@title Reading and Cleaning Data\n",
        "def clean_fireData(fire):  \n",
        "  #drop duplicates\n",
        "  duplicates = fire.duplicated(subset=None, keep='first')\n",
        "  fire=fire.drop_duplicates()\n",
        "\n",
        "  #drop columns missing lots of data\n",
        "  fire = fire.drop(columns=['DETECTOR', 'STRUCTURE STATUS'])\n",
        "\n",
        "  #drop rows with missing data (not many, once columns are removed above)\n",
        "  #fire = fire.dropna()\n",
        "\n",
        "  #convert necessary columns to datetime objects\n",
        "  cols_to_convert_to_datetime = ['DATE OF CALL', 'TIME OF CALL', 'DATE OF DISPATCH', 'TIME OF DISPATCH', 'DATE OF ARRIVAL', 'TIME OF ARRIVAL', 'DATE UNIT CLEARED', 'TIME UNIT CLEARED']\n",
        "  for col in cols_to_convert_to_datetime:\n",
        "    fire[col]=pd.to_datetime(fire[col])\n",
        "\n",
        "  #make broader categories of property use\n",
        "  fire['PROPERTY_USE_GENERAL']=fire['PROPERTY USE'].apply(lambda x: x if checkIfInTopPlaces(x)==True else 'Other')\n",
        "\n",
        "  #binarize property use broader categories\n",
        "  go_through_set('PROPERTY_USE_GENERAL', fire)\n",
        "\n",
        "  #create new columns for hour and month of call\n",
        "  fire['CALL HOUR']=fire['TIME OF CALL'].apply(lambda x: x.hour)\n",
        "  fire['CALL MONTH']=fire['DATE OF CALL'].apply(lambda x: x.month)\n",
        "  fire['CALL DAY OF WEEK']=fire['DATE OF CALL'].apply(lambda x: x.dayofweek)\n",
        "\n",
        "  return fire\n",
        "\n",
        "\n",
        "fire = pd.read_csv('fire.csv')\n",
        "\n",
        "props = fire['PROPERTY USE']\n",
        "counts = props.value_counts()\n",
        "counts.to_string()\n",
        "topPlaces = counts[0:30]\n",
        "topPlacesDf = pd.DataFrame(topPlaces)\n",
        "topPlacesDf['Property Type']=topPlacesDf.index\n",
        "topPlacesDf['Count']=topPlacesDf['PROPERTY USE']\n",
        "topPlacesDf = topPlacesDf.drop(columns='PROPERTY USE')\n",
        "topPlacesDf = topPlacesDf.drop(index='Property Use, other')\n",
        "def checkIfInTopPlaces(x):\n",
        "  for place in topPlacesDf['Property Type']:\n",
        "    if x==place:\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "fire = clean_fireData(fire)\n",
        "fire.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EXPOSURE</th>\n",
              "      <th>ADDRESS</th>\n",
              "      <th>INCIDENT #</th>\n",
              "      <th>INCIDENT TYPE</th>\n",
              "      <th>INCIDENT TYPE CATEGORY</th>\n",
              "      <th>PROPERTY USE</th>\n",
              "      <th>ENGINE AREA</th>\n",
              "      <th>DATE OF CALL</th>\n",
              "      <th>TIME OF CALL</th>\n",
              "      <th>DATE OF DISPATCH</th>\n",
              "      <th>TIME OF DISPATCH</th>\n",
              "      <th>DATE OF ARRIVAL</th>\n",
              "      <th>TIME OF ARRIVAL</th>\n",
              "      <th>DATE UNIT CLEARED</th>\n",
              "      <th>TIME UNIT CLEARED</th>\n",
              "      <th>CIVILIAN INJURY</th>\n",
              "      <th>CIVILIAN FATALITY</th>\n",
              "      <th>FIRE PERSONNEL INJURY</th>\n",
              "      <th>FIRE PERSONNEL FATALITY</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>LOCATION</th>\n",
              "      <th>PROPERTY_USE_GENERAL</th>\n",
              "      <th>Other</th>\n",
              "      <th>Motor vehicle or boat sales, services, r</th>\n",
              "      <th>High school/junior high school/middle sc</th>\n",
              "      <th>Service station, gas station</th>\n",
              "      <th>Parking garage, (detached residential ga</th>\n",
              "      <th>Church, mosque, synagogue, temple, chape</th>\n",
              "      <th>Convenience store</th>\n",
              "      <th>Manufacturing, processing</th>\n",
              "      <th>Highway or divided highway</th>\n",
              "      <th>Street, other</th>\n",
              "      <th>Mercantile, business, other</th>\n",
              "      <th>24-hour care Nursing homes, 4 or more pe</th>\n",
              "      <th>Warehouse</th>\n",
              "      <th>Elementary school, including kindergarte</th>\n",
              "      <th>Residential street, road or residential</th>\n",
              "      <th>Vehicle parking area</th>\n",
              "      <th>Restaurant or cafeteria</th>\n",
              "      <th>Vacant lot</th>\n",
              "      <th>Open land or field</th>\n",
              "      <th>Residential, other</th>\n",
              "      <th>Business office</th>\n",
              "      <th>Schools, non-adult</th>\n",
              "      <th>Undetermined</th>\n",
              "      <th>Bar or nightclub</th>\n",
              "      <th>Street or road in commercial area</th>\n",
              "      <th>Outside or special property, other</th>\n",
              "      <th>Hotel/motel, commercial</th>\n",
              "      <th>Food and beverage sales, grocery store</th>\n",
              "      <th>1 or 2 family dwelling \\ House \\ Residen</th>\n",
              "      <th>Multifamily dwellings \\ Apartments</th>\n",
              "      <th>CALL HOUR</th>\n",
              "      <th>CALL MONTH</th>\n",
              "      <th>CALL DAY OF WEEK</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No</td>\n",
              "      <td>PLYMOUTH RD / MEYERS RD, Detroit</td>\n",
              "      <td>16</td>\n",
              "      <td>700 - False alarm or false call, other</td>\n",
              "      <td>FALSE ALARM, FALSE CALL</td>\n",
              "      <td>Street, other</td>\n",
              "      <td>E42</td>\n",
              "      <td>2015-01-01</td>\n",
              "      <td>2020-05-14 03:02:47</td>\n",
              "      <td>2015-01-01</td>\n",
              "      <td>2020-05-14 03:04:11</td>\n",
              "      <td>2015-01-01</td>\n",
              "      <td>2020-05-14 03:11:28</td>\n",
              "      <td>2015-01-01</td>\n",
              "      <td>2020-05-14 03:14:06</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-9258236.220</td>\n",
              "      <td>5217052.339</td>\n",
              "      <td>(5217052.33870992, -9258236.21953809)</td>\n",
              "      <td>Street, other</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>No</td>\n",
              "      <td>18321 FAUST AVE, Detroit</td>\n",
              "      <td>53</td>\n",
              "      <td>745 - unintentional</td>\n",
              "      <td>FALSE ALARM, FALSE CALL</td>\n",
              "      <td>1 or 2 family dwelling \\ House \\ Residen</td>\n",
              "      <td>E59</td>\n",
              "      <td>2015-01-01</td>\n",
              "      <td>2020-05-14 16:08:33</td>\n",
              "      <td>2015-01-01</td>\n",
              "      <td>2020-05-14 16:10:23</td>\n",
              "      <td>2015-01-01</td>\n",
              "      <td>2020-05-14 16:13:44</td>\n",
              "      <td>2015-01-01</td>\n",
              "      <td>2020-05-14 16:14:45</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-9264467.798</td>\n",
              "      <td>5224699.499</td>\n",
              "      <td>(5224699.4990991, -9264467.79848532)</td>\n",
              "      <td>1 or 2 family dwelling \\ House \\ Residen</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>No</td>\n",
              "      <td>18050 HAYES ST, Detroit</td>\n",
              "      <td>75</td>\n",
              "      <td>710 - Malicious, mischievous false call, other</td>\n",
              "      <td>FALSE ALARM, FALSE CALL</td>\n",
              "      <td>1 or 2 family dwelling \\ House \\ Residen</td>\n",
              "      <td>E50</td>\n",
              "      <td>2015-01-01</td>\n",
              "      <td>2020-05-14 21:58:48</td>\n",
              "      <td>2015-01-01</td>\n",
              "      <td>2020-05-14 21:59:41</td>\n",
              "      <td>2015-01-01</td>\n",
              "      <td>2020-05-14 22:03:37</td>\n",
              "      <td>2015-01-01</td>\n",
              "      <td>2020-05-14 22:04:47</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-9235639.782</td>\n",
              "      <td>5225437.056</td>\n",
              "      <td>(5225437.05637783, -9235639.78220764)</td>\n",
              "      <td>1 or 2 family dwelling \\ House \\ Residen</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  EXPOSURE                           ADDRESS  ... CALL MONTH CALL DAY OF WEEK\n",
              "0       No  PLYMOUTH RD / MEYERS RD, Detroit  ...          1                3\n",
              "1       No          18321 FAUST AVE, Detroit  ...          1                3\n",
              "2       No           18050 HAYES ST, Detroit  ...          1                3\n",
              "\n",
              "[3 rows x 56 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4HGhMTI5Kt7"
      },
      "source": [
        "I found the dataset [here](https://data.world/detroit/detroit-2015-fire-data). The columns are: exposure, address, incident number, incident type, incident type category, property use, engine area, date of call, time of call, date of dispatch, time of dispatch, date of arrival, time of arrival, date unit cleared, time unit cleared, detector, number civilian injury, number civilian fatality, number fire personell injury, number fire personell fatality, structure status, latitude, longitude, and location (both latitude and longitude). These columns are mostly self explanatory, but I did have to study to learn that \"incident type category\" is more broad categories than \"incident type.\"\n",
        "\n",
        "The first step in my data prepping process was to remove one duplicate row. Then I removed the columns \"Detector\" and \"Structure Status\" because they were both mostly null values. Once I had removed them, only a few columns (less than 10) contained null values, and they were not in any of the columns I needed for my classification models.\n",
        "\n",
        "I converted all time and date columns to datetime objects and created new columns \"Call Hour,\" \"Call Month,\" and \"Call Day of Week\" by extracting this information from the datetimes. \n",
        "\n",
        "The hardest step of the data prep process was that I wanted to use the information from the \"Property use\" column. Previously I've written functions that quickly binarize all the value that appear in the column, but there were too many in this column to do that. There were over 40, and many only had one or two ocurrances. So, I created a new dataframe of the top 25 most common property uses and grouped the rest together in an \"Other\" category. Then I only binarized these top 25 (I experimented with running the models with more or less than 25, and found it to be an appropriate threshold.) \n",
        "\n",
        "I used the following features as independent variables: latitude, longitude, call hour, call month, call day of week, and the binarized property uses. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCO6GQH3_hyq"
      },
      "source": [
        "#Model Fitting\n",
        "I found myself writing the same code over and over again for different classifiers and trying to figure out which one was the closest to solving my problem. This is what inspired me to create the new benchmark statistic as well as to write a function that tried all of the classifiers and output the best one by each measurement. I first did this with a standard test/train split of the data - disregarding the imbalanced number of false alarms, and got results that are slightly better than chance. Next, I balanced the data - making sure to balance AFTER the test/train split to avoid data leakage - and ran the new training and testing data through the same loop. The results did not improve; they were slightly worse. But in both cases, The Random Forest Classifier stood out as the best model, with GBC also showing high precision. \n",
        "\n",
        "This finding corresponds with the results in [this](https://towardsdatascience.com/comparing-different-classification-machine-learning-models-for-an-imbalanced-dataset-fdae1af3677f) article from <i>Toward Data Science</i> which discusses the best machine learning models for imbalanced datasets. I learned from the article that these two classifiers are actually fairly similar. Both are a forest of decision trees and each tree takes into account different subsets of variables and training data. The difference is that each time the Gradient Boosting Classifier builds a tree, it attempts to fix the mistakes made in the previous ones. \n",
        "\n",
        "Because I did not get much better results with the balanced data, I stuck to the original imbalanced data when tuning hyperparameters. I used a grid search with code from [this](https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74) article, also from <i>Toward Data Science</i>, and found the following ideal hyperparameters: \n",
        "\n",
        "<ul>\n",
        "<li>bootstrap: True</li>\n",
        "<li>max_depth: 40</li>\n",
        "<li>min_samples_leaf: 2</li>\n",
        "<li>min_samples_split: 10</li>\n",
        "<li>n_estimators: 2000</li>\n",
        "</ul>\n",
        "\n",
        "I ran the same grid search on the GBC model and found these hyperparameters:\n",
        "<ul>\n",
        "<li>learning_rate: .001</li>\n",
        "<li>max_depth: 60</li>\n",
        "<li>min_samples_leaf: 4</li>\n",
        "<li>min_samples_split: 5</li>\n",
        "<li>n_estimators: 1600</li>\n",
        "<li>subsample: .25</li>\n",
        "</ul>\n",
        "\n",
        "Because the grid searches took almost an hour to run, and 4 and a half hours, respectively, I commented them out, but they can be found below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ta3vk2molAz",
        "outputId": "96ecf7a8-03e6-4a15-e3fb-1c9a06147b8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "#@title Finding the best model: imbalanced data\n",
        "X_labels=['X', 'Y', 'CALL DAY OF WEEK', 'CALL HOUR', 'CALL MONTH']\n",
        "for label in topPlacesDf['Property Type']:\n",
        "  X_labels.append(str(label))\n",
        "X=fire[X_labels]\n",
        "\n",
        "\n",
        "y=fire['INCIDENT TYPE CATEGORY'].apply(lambda x: 1 if (x=='FALSE ALARM, FALSE CALL') else 0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train=scaler.transform(X_train)\n",
        "X_test=scaler.transform(X_test)\n",
        "\n",
        "classifiers=[LogisticRegression, RandomForestClassifier, GaussianNB, BernoulliNB, DecisionTreeClassifier, BaggingClassifier, ExtraTreesClassifier, svm.SVC, Perceptron, LDA, MLPClassifier, ABC, GBC, Perceptron]\n",
        "accuracy=[]\n",
        "precision=[]\n",
        "recall=[]\n",
        "f1=[]\n",
        "benchmark=[] #precision*3 + recall /4\n",
        "auc=[]\n",
        "\n",
        "show_max_stats(X_train, X_test, y_train, y_test, classifiers, accuracy, precision, recall, f1, benchmark, auc)\n",
        "'''print(accuracy)\n",
        "print(precision)\n",
        "print(recall)\n",
        "print(f1)\n",
        "print(benchmark)'''\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------\n",
            "max accuracy=RandomForestClassifier at 0.7087\n",
            "max precision=GBC at 0.691\n",
            "max recall=Perceptron at 0.4679\n",
            "max f1=DecisionTreeClassifier at 0.4545\n",
            "max benchmark=GBC at 0.5624\n",
            "max auc=RandomForestClassifier at 0.622\n",
            "----------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'print(accuracy)\\nprint(precision)\\nprint(recall)\\nprint(f1)\\nprint(benchmark)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k06AK8nzK2w2",
        "outputId": "726c0058-0521-4482-a818-9de9ae2c1b50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "#@title Finding the best model: balanced data { form-width: \"20px\" }\n",
        "fire['Class Label']=fire['INCIDENT TYPE CATEGORY'].apply(lambda x: 1 if (x=='FALSE ALARM, FALSE CALL') else 0)\n",
        "\n",
        "X_labels2=['X', 'Y', 'CALL DAY OF WEEK', 'CALL HOUR', 'CALL MONTH', 'Class Label']\n",
        "for label in topPlacesDf['Property Type']:\n",
        "  X_labels2.append(str(label))  \n",
        "X2=fire[X_labels2]\n",
        "y2=fire['Class Label']\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2=train_test_split(X2, y2, random_state=0)\n",
        "\n",
        "positive=X_train2[X_train2['Class Label']==1]\n",
        "negative=X_train2[X_train2['Class Label']==0]\n",
        "\n",
        "df_negative_upsampled = resample(negative, replace=True, n_samples=4829, random_state=123)\n",
        "X_train2=pd.concat([positive, df_negative_upsampled])\n",
        "y_train2=X_train2['Class Label']\n",
        "X_train2=X_train2.drop(columns='Class Label')\n",
        "X_test2=X_test2.drop(columns='Class Label')\n",
        "\n",
        "scaler=StandardScaler().fit(X_train2)\n",
        "X_train2=scaler.transform(X_train2)\n",
        "X_test2=scaler.transform(X_test2)\n",
        "\n",
        "\n",
        "classifiers=[LogisticRegression, RandomForestClassifier, GaussianNB, BernoulliNB, DecisionTreeClassifier, BaggingClassifier, ExtraTreesClassifier, svm.SVC, Perceptron, LDA, MLPClassifier, ABC, GBC, Perceptron]\n",
        "accuracy.clear()\n",
        "precision.clear()\n",
        "recall.clear()\n",
        "f1.clear()\n",
        "benchmark.clear() #precision*3 + recall /4\n",
        "auc.clear()\n",
        "\n",
        "show_max_stats(X_train2, X_test2, y_train2, y_test2, classifiers, accuracy, precision, recall, f1, benchmark, auc)\n",
        "'''print(accuracy)\n",
        "print(precision)\n",
        "print(recall)\n",
        "print(f1)\n",
        "print(benchmark)'''\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------\n",
            "max accuracy=GaussianNB at 0.6959\n",
            "max precision=GaussianNB at 0.5827\n",
            "max recall=ExtraTreesClassifier at 0.7185\n",
            "max f1=RandomForestClassifier at 0.5534\n",
            "max benchmark=RandomForestClassifier at 0.5172\n",
            "max auc=RandomForestClassifier at 0.6422\n",
            "----------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'print(accuracy)\\nprint(precision)\\nprint(recall)\\nprint(f1)\\nprint(benchmark)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhQi3gY4643E",
        "outputId": "7b02fbfb-2112-4333-92f0-da2257d97b46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#@title Hyperparameters Grid Search: Random Forest Model { form-width: \"20px\" }\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "max_features = ['auto', 'sqrt']\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "bootstrap = [True, False]\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "print(random_grid)\n",
        "\n",
        "'''rf = RandomForestClassifier()\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "rf_random.fit(X_train2, y_train2)\n",
        "\n",
        "rf_random.best_params_'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rf = RandomForestClassifier()\\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\\nrf_random.fit(X_train2, y_train2)\\n\\nrf_random.best_params_'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X6irma_OAor",
        "cellView": "form",
        "outputId": "73e4b908-51cf-4626-85df-21bc27084d70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#@title Hyperparameters Grid Search: GBC model { form-width: \"20px\" }\n",
        "\n",
        "loss=['deviance', 'exponential']\n",
        "learning_rate=[.1, .05, .001, .2, .3]\n",
        "max_depth=[2, 4, 8, 12]\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "subsample=[.25, .5, 1.0]\n",
        "min_samples_split=[2, 5, 10]\n",
        "min_samples_leaf=[1, 2, 4]\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "\n",
        "\n",
        "random_grid = {'loss':loss, 'learning_rate':learning_rate, 'max_depth':max_depth, 'n_estimators':n_estimators, 'subsample':subsample, 'min_samples_split':min_samples_split, 'min_samples_leaf':min_samples_leaf, 'max_depth':max_depth} \n",
        "\n",
        "print(random_grid)\n",
        "\n",
        "'''gbc = GBC()\n",
        "gbc_random = RandomizedSearchCV(estimator = gbc, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "gbc_random.fit(X_train, y_train)\n",
        "\n",
        "gbc_random.best_params_'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'loss': ['deviance', 'exponential'], 'learning_rate': [0.1, 0.05, 0.001, 0.2, 0.3], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'subsample': [0.25, 0.5, 1.0], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gbc = GBC()\\ngbc_random = RandomizedSearchCV(estimator = gbc, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\\ngbc_random.fit(X_train, y_train)\\n\\ngbc_random.best_params_'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0UOEfAq_mhi"
      },
      "source": [
        "#Model Evaluation and Selection\n",
        "Using a grid search to find the best hyperparameters strengthened both models.\n",
        "\n",
        "####<u>Random Forest Model</u>\n",
        "The hyperparameters decreased the number of false positives from 398 to 263 and increased the benchmark score from .543 to .570, an increase of almost 5%. This came at the cost of some of the true positives - the original hyperparameter-less random forest model classified a record 603 false alarms as actual false alarms, and this number decreased to 506 in the improved model. \n",
        "\n",
        "The main advantage of the Random Forest Model over the GBC is that it is slightly faster, and time is of the essence in a fire department. It also does have a slightly higher AUC, but because false positives have a much higher cost, I do not think this slight difference strongly supports its use over the GBC. \n",
        "\n",
        "####<u>Gradient Boosting Model</u>\n",
        "Adding hyperparemeters to the GBC model increased the benchmark score from .563 to .584, an increase of over 3%, and it classified a significantly more false alarms correctly at 461 (versus 292). However, the number of false positives did increase from 130 to 211. Because this model has the highest benchmark and F1 scores, I consider it to be the most useful model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1too3WDnLKy8",
        "outputId": "44c49f9b-2865-446a-9fd0-7586a7c069a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "#@title Final Model A: Random Forest Classifier\n",
        "model=RandomForestClassifier(n_estimators=2000, min_samples_split=10, min_samples_leaf=2, max_features='auto', max_depth=40, bootstrap=True, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred=model.predict(X_test)\n",
        "evaluate_binary(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------\n",
            "Accuracy:  0.7177\n",
            "Precision:  0.6601\n",
            "Recall:  0.3049\n",
            "F1:  0.4171\n",
            "Benchmark: 0.5713\n",
            "AUC: 0.6135\n",
            "---------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x144 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caz6kfUVatoJ",
        "outputId": "83ed82fc-cd7c-4dc7-da93-bba78449c3b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "#@title Final Model B: Gradient Boosting Classifier\n",
        "model=GBC(learning_rate=.001, loss='deviance', max_depth=60, min_samples_leaf=4, min_samples_split=5, n_estimators=1600, subsample=.25, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred=model.predict(X_test)\n",
        "evaluate_binary(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------\n",
            "Accuracy:  0.7203\n",
            "Precision:  0.6913\n",
            "Recall:  0.2814\n",
            "F1:  0.4\n",
            "Benchmark: 0.5888\n",
            "AUC: 0.6095\n",
            "---------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAACfCAYAAAD3XhIVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAfyklEQVR4nO3deVyU1f7A8c/M4IY4ICjDiAupaaQp1Chqlia5XMNMb6bRgpqpKdzslkoumFuG2XILU8s1U9MsqTAF07xqPxVXFDEXREyZQFllR5jfH9ymiBkkcIAZv+/X63kp55znec4Z8cvhPOc5R2EwGAwIIYSwWcraroAQQgjLkkAvhBA2TgK9EELYOAn0Qghh4yTQCyGEjZNAL4QQNs6utivwdzXyDqztKog6Jv1IWG1XQdRRDasZ4czFm7wT1vU9Z3WBXgghaoyqXrUvMWnSJK5evYpSqcTe3p7Zs2fj6elJQkICwcHBZGRk4OTkRGhoKB4eHgBVzjNHhm6EEMIcpcr08TeEhoby3XffER4eztixY5kxYwYAc+bMwd/fn8jISPz9/QkJCTGeU9U8s834WzUWQoi7icrO9PE3NGnSxPj37OxsFAoFqampxMXF4efnB4Cfnx9xcXGkpaVVOa8iMnQjhBDmmOm9Z2VlkZWVVS5drVajVqvLpc+cOZOff/4Zg8HAypUr0ev1aDQaVKrS66tUKlxdXdHr9RgMhirlOTs7m22GBHohhDDHTKBft24dYWHlH8gGBgYSFBRULn3hwoUAhIeHs3jxYl599dU7W8/bkEAvhBDm2Jl+GBsQEMCwYcPKpZvqzf/ZU089RUhICG5ubiQnJ1NcXIxKpaK4uJiUlBS0Wi0Gg6FKeRWRMXohhDDHzMNYtVpNy5Ytyx1/DfQ5OTno9Xrj13v27MHR0REXFxc8PT2JiIgAICIiAk9PT5ydnaucVxGFtS1TLPPoxV/JPHphTrXn0fcPNZmet2t6pc6/ceMGkyZNIi8vD6VSiaOjI9OnT6dTp07Ex8cTHBxMVlYWarWa0NBQ2rZtC1DlPHMk0AurJ4FemFPtQD/ofZPpeTv/Xb0L1zAZoxdCCHP+5pz5ukoCvRBCmCOBXgghbNwdWAKhLpBAL4QQ5kiPXgghbJtCaRsz0CXQCyGEGUqVBHohhLBpSunRCyGEbZMevRBC2Djp0QshhI1TKBW1XYU7QgJ9DXu8pyevj36c+9pqaapuxI30bA7FJLBgxQ/8cuk3ANxdnXh9TH8evL81D9zrjn2j+nQcHMIVfdnNBVprm7Jk2gi6dmxJ86YO5OQVcvaSnvfW7iLyQFyZsub2uPQZuYhT569ZprGiynZF7mTHD9uJOxNLWloqblotvo8PYNz4CTRu7GAsl5WZyfvvLean3T+SX1BA165eTJ3+Jvd26FjmevqkJJZ+/B+ORB8mPT0NjZuWgQMHMfblCdjb29d086zG7+u+WzsJ9DXM2dGeE2d/5dOv9nM9PZtWbk15Y8wA/rvudbo98zZX9Om0bdWc4f29OXH2V34+EU//Xp4mr9W4UQNSM7J5a+n3XEvOQO3QkDHDHib840mMev0zvt0TU6b8598eYtXXB8qkXbiSYrG2iqpbt3Y1Wq2WoCmvodG48cvZOJZ/EsaR6MN8vuFLlEolBoOBoMkTSUq6RvCM2ajValat/JRxY15ky9ffonFzAyA3N5fx48Zw61YRk4NexU2r5UzsaZYt/ZjEK4m8+96Htdzaukt69KJKtuw8xpadx8qkHY1N5FR4CMMe9+Y/6/dw4PhFPB4v3Vdy9LCeZgP92Uu/8crcjWXSduw/wy8Rc3nhyR7lAn1SSgbRpy/fucYIi/lo6fIyS8/qunXH0dGJWTOmcyT6MD49erL3p92cPHGcz1avo7tPDwC6eHkzeIAva1avJHjGLABOnjjOlcTLLPt0Fb0e7g1Ad58eZGZm8vna1eTl5dGoUaOab6QVsJUxettohZVLy8wB4NatEgCqs6BocXEJmdl5FBeX3JG6idphan3xTp0fACAlJRmAvT/tobmrqzHIQ+n+pH36PsbePbuNaUVFRQA4ODjwZ02aqCkpKanW95utU6qUJg9rU2M1Tk9P5+zZs5w9e5b09PSaum2dpVQqqGenol3r5oTNehb99Uy27DxapWspFApUKiUalya8OX4Q97ZxZdnm/5Yr9/KIR8g4/AGp//c+O1YE8bB3u+o2Q9Sgo0ejAWjbtvTfLf7iRdq371CuXLv27dHrk8jNKe1A9OjZi9ZtPPjw/SXEX7xIbk4Ohw8dZOMXnzPimVEyRl8BpVJp8rA2Fh+6uXLlCrNnzyYuLg5XV1cAUlJSuP/++5k7dy4eHh6WrkKdtG/9VB66vzUAF6+k8I8JH3E9PbtK13p7ylNMedEXgJs5+bwYvIa90efLlNkYEc2O/bHor2fSSuvMawG+7FjxL554JYz9xy5UrzHC4pKTk/kk7CN69Oxl7NlnZmbSwt29XFlHRyegdANr+8aNadCgAWvXb+T1KUEMH/qEsdzwf47gzVkhNdMAKyVj9JU0bdo0/P39WbNmjfEnYUlJCd9//z3Tp09n8+bNlq5CnfTSrHWoGzfknpbNePUFX7YvC6TfmA/KzaypjLANP/FV5DE0Lmqe8+vO2rdH4z91FTv2x/5xv9mf/3HCiXgi9p7i2NaZvDXZD9+xH9yJJgkLyc3JYUrQK9ipVMxbsOhvn19QUMC016eQlpbKwncWo9W2IPb0KVYsW4rKTsWskLkWqLVtsJVZNxb/HSQjI4Mnn3yyzK87SqWSoUOHkpmZaenb11nnEpI5EpvIlp3HGDzhYxrbN+CNsQOqdK1rKRkcj7vCjv2xPD99NdGnL7PotacqPCc7t4Ad+2N5qFPrKt1T1Iz8/HyCJk/k6q9XWfbpKuNMGijdiDorM6vcOZmZGcZ8gG1fb+XokWiWLvsMvyFDeUjXjYAxL/H61GC+2vwl5375pWYaY4UUSoXJw9pYPNA7OTkRERFR5oGPwWDgu+++u+2O6XeLzOw84n+9QbtWze7I9Y7HXaFdq+aVKivP4equoqIi3njtX8SdiWXp8k/LzY1v17498fHlh90uxcej1bbAvnFjAC5cOIda7Uir1mV/qHd+oEtp+UvxFmqB9VMqFSYPa2PxQP/OO+/w1Vdf4ePjw5AhQxgyZAg+Pj5s3bqVd955x9K3twquzk3o6KHh0q83qn0thUJBL6+2XLpa8bWaNG7I4Ec6c/RMYrXvKe68kpISZkx/g+jDh/jw40/o0tWrXJm+j/mSkpzM0SPRxrTs7Gz+u/cn+jzWz5jWrFlzsrIyuZJY9t/69KnS6bcajcZCrbB+KpXS5GFtLD5G7+Hhwbp160hLS0Ov1wOg1WpNTh+7G2x+72VO/PIrsReukZWdz71tXAl67jFuFRfzn/V7jOWGPV76H9vbs7QXNrD3/dxIz+Z6ejYHjl0EYOaEwTg72nPw5CV+S83CzUVNwFM90XVuw+gZ64zXmvKCL/d6uLLvyAWSrmfSuoUzU17wRdNMzZiZ6xB1z9sL5hIVuZOXx0+kUaNGnIo5aczTaNzQuLnR97F+dPXyZkbwVF57fRpqtZrVKz/FYDAwZuw4Y/knnxrG+nVrmPzKeF4ePxE3rZa4M7F8uvwT7u/UCS/vB2ujiVZBpbK+3rspCoOVTaJt5B1Y21WoltdHP87w/g/StlUz6tvZcTU5nX1HL/Du6qgyD2LNLVmw7+gFBr78HwCe6PMAgf59ub99CxwdGpKcepNT56/x/ppdHIy5ZDxn8KOdeWNMf+5to8HRoRFZOfkcjLlE6Gc7baJHn37E9Gdlzf7Rvx9JSaaXppg4KZBXJgcBkJmRwXtLQvlp924KCwvo0tWLN6a9Scf77itzTvzFiyz/5GNiYk6SkZ6Oxk1L38f68fL4iagdHS3entrSsJpd2c6zdplMj13Qv3oXrmES6IXVs8VAL+6M6gb6rnN2m0yPmetbvQvXMFkCQQghzLDGB6+mSKAXQggzbGWMXgK9EEKYIT16IYSwcRLohRDCxlnjnHlTzAb6qVOnolDc/qfZ4sWL72iFhBCirqhujz49PZ1p06Zx5coV6tevT5s2bZg3bx7Ozs6cPHmSkJAQCgoKcHd3591338XFxQWgynlm22Euo02bNrRu3fq2hxBC2KrqLoGgUCgYN24ckZGRfP/997Rq1YolS5ZQUlLC1KlTCQkJITIyEp1Ox5IlSwCqnFcRsz36wECZry6EuLtVd+jGyckJHx8f49deXl5s2rSJ2NhYGjRogE6nA2DUqFH4+vqyaNGiKudVpNJj9IWFhSQkJJCenl5mgbKePXtWvtVCCGFFVGZ671lZWWRllV85VK1Wm12ssaSkhE2bNtGvXz/0ej0tWrQw5jk7O1NSUkJGRkaV85ycnMy2o1KB/ujRo0yZMoXCwkKys7NxcHAgJycHNzc3du82/eaYEEJYO3PDNOvWrSMsrPwb2YGBgQQFBZk8Z/78+djb2/P888+za5fppRUspVKBftGiRYwbN47Ro0fTrVs3oqOjCQsLkw2FhRA2zc7MC1MBzwcwbNiwcunmevOhoaEkJiayfPlylEolWq2WpKQkY35aWhpKpRInJ6cq51WkUgNQly9f5sUXXyyTNn78eNauXVuZ04UQwiqpFAqTh1qtpmXLluUOU4H+/fffJzY2lqVLl1K/fn0AOnfuTH5+PkePlu4T/eWXXzJo0KBq5VWkUj36Jk2akJ2djVqtpnnz5ly8eBEnJydyc3Mrc7oQQlil6k6vvHDhAitWrMDDw4NRo0YB0LJlS5YuXcrixYuZM2dOmWmSpfdUVimvIpVavXLhwoV06dKFIUOGsGrVKlatWoWdnR29e/fm7bffrs7n8LfJ6pXir2T1SmFOdVevfHrNcZPpW8dY1xr+lfoYZs6cafz7Sy+9RNeuXcnJyeGRRx6xWMWEEKK2mZt1Y22q9PPu9zmcQghhy+zupkDv7+9vdjmEDRs23NEKCSFEXXFXLWo2YsSIMl9fv36dr7/+miFDhlikUkIIURfcVUM3puaLDhw4kDfffFOWShBC2Cw7pY2vXnk7Go2Gc+fO3cm6CCFEnXJXDd1s3bq1zNf5+flERUXh5eVlkUpVZP3ambcvJO4q6TmFtV0FUUdpHetX6/y7aujm22+/LfO1vb093t7ejB492hJ1EkKIOuGumnWzfv16S9dDCCHqHFvp0VfqSUP37t1NpssSxUIIW6ZSKkwe1qZSPfqioiKTaSUlJXe8QkIIUVfUM7N6pbWpMND//qJUYWEhzz33XJm83377DW9vb4tWTgghapONxPmKA/2IESMwGAycPn2ap59+2piuUChwcXGhR48eFq+gEELUFmscpjGlwkD/+4tSXbt2pV27djVSISGEqCtsZeimUg9jN23axPHjZZfrPH78OAsXLrRIpYQQoi4wt/GItalUoI+IiKBz585l0jp37kxERIRFKiWEEHWBndL0YW0qNetGoVDw1/1JiouLZdaNEMKmmdsz1tpU6meTTqfjww8/NAb2kpISPvroI1mXXghh0+yUCpOHtan0DlMTJkygd+/etGjRgqSkJFxdXVm+fLml6yeEELXGGoO6KZUK9G5ubmzbto1Tp06h1+tp1qwZP/74I08//TQHDhywdB2FEKJW3FWBHiAjI4OYmBi2bdvGuXPn0Ol0ZfaSFUIIW3NXzKMvKipiz549bNu2jQMHDtC6dWueeOIJ9Ho9H374IS4uLjVVTyGEqHF3RY/+4YcfRqFQMHz4cIKCgujUqRNQOq9eCCFsnTXOmTelwlk3HTt25ObNm8TExHD69GkyMzNrql5CCFHrlArTh7WpsEe/fv16rl27Rnh4OKtXr2bBggX07t2b3Nxcbt26VVN1FEKIWmEre8bethXu7u5MnjyZqKgo1q5dS/PmzVEqlTz55JMsXry4JuoohBC1QqlQmDyszd/aHFyn06HT6Zg1axa7du0iPDzcUvUSQohaZytj9H8r0P+uQYMG+Pn54efnd6frY/MyU1PY9+0mrsWf47fEeIoKC3gjbBNNXbVlykVt/Ixrl85x7dJ58rKz+Oek6TzY9x/lrldYkM+uTSs5fXAvuTczaaZtyaNP+eP1SP9yZeOi97Nn6zquX0vEwdEZne8T9Bn2HEqlymLtFXfO1H9N5Mihn3l+zMuMe+VfZfLOnI5h7WfLiIs9RfGtW2jd3Xl+zHh8B5T9nklMuMTqFWGcOHaE/Pw8NBotQ58eydOjnq/JplgNu7s50IuqS/3tGqcP7sW9bQfaeHbhYswRk+UO7vwGrUd77nuwJyf2RZq93sYls7lyPo7+o16iWYtWnDm8j68+XggGA16PDjCWu3Aymo3vzeGhfoMZ/OJkki5fYNemzyjIy2PQ8xPueDvFnbU78gfiL5wzmXfwwD5mT3sV34GDmT3/Hezq1SMx4RKFhQVlyv0Sd4Z/T34Jrwe7MXXmWzg4NOHqr4nk5ebWRBOskjUO05gigb6GeXh2ZcZn2wA4sjvCbKCfvXY7SqWS1N+umg30l385xYWYI2V6+/d27UZW2nV2blhBl96+xt565MZPaXPfAwyb8AYAbTt7U5ifx96v1/Ow39M0cZJ3Iuqqm1mZhH2wmMDXpjF/9vQyebk5OYTOn83Qp0cR9O8/8nTdy+7nXFJSwqK5M3hQ58OCd/9jTPfWmd4PWpSq7tBNaGgokZGRXLt2je+//54OHToAkJCQQHBwMBkZGTg5OREaGoqHh0e18ipiG4+UrYiykk/xK1Pu1/NxAHTw8imTfq9Xd26mpxrzM26koL98sdxwjtejAyguvsX5E9GVqpOoHSvCPuCedu3xHTi4XN7e3VFkpKcx8rmACq9x8tgREhMu8Yz/i5aqpk2q7ubgvr6+bNiwAXd39zLpc+bMwd/fn8jISPz9/QkJCal2XkUk0Fux33vrKrt6ZdLt7OoDkPxrAgApV0v/1LS+p0w5Z1ct9Ro0JOXqZQvXVFTVqZPHifzhe6ZMM73cyOmY46jVjly6eJ4xzw6jX08vRvg9ztrPllFcXFymHEBhYQGvjH0O357ePDWwDx8tWURBfn6NtMUamdt4JCsri6tXr5Y7srKyypyv0+nQass+f0tNTSUuLs74jNPPz4+4uDjS0tKqnHc7MnRjxZq1aAXAlQtxdPT+o1d/5fwZAPKyb5b5s1Fjh3LXaNTYwZgv6paioiLeXzSPkc8F0LrNPSbL3Lh+nfyCfObPDubFlybQ4b77ORZ9kM9XryD7ZhaB/xvOuXH9OgBzZ05l2IhnGT95CufOnmHNiqWkJP9WZjhH/MHcEgjr1q0jLCysXHpgYCBBQUEVXlOv16PRaFCp/tdRU6lwdXVFr9djMBiqlOfs7FxxO27bUlFnte+qo7l7G7av+YhGjWfQvEVrzkTv49TPu4HSDWOE9dr0+WoKCvJ5Ycx4s2UMhhIKCwoYNzGIZ/43fOP9UDeyMjMJ3/olo8dPwsGhCQZD6V4S/Qf5MXZCoLFcSXExny79kMSES7S5p63lG2VlzD2MDQgIMO6p/WdqtdrSVaqSWh26GTJkSG3e3uqpVHb4vz6Xeg0asmLWZBaMHcKuTSsZ4P8yAE2alj5gbdi4CQB5OdnlrpGXk00jhyY1V2lRKcm/6fli7WeMnRhIYVEhN29mcfNm6bBAUVERN29mUVxcjNrRCQCdT9mHr918enHr1i0uX4oHMF+uRy8ALpw7a9H2WCtzQzdqtZqWLVuWOyoT6LVaLcnJycahteLiYlJSUtBqtVXOux2L9+gvXrxoNi89Pd3St7d5ri09CHp3FekpegoL8mmmbcWZ6H0AtO5Yus+vppUHUDpm37pDJ+O56Sl6igrycW3pUdPVFreRdO0qhQUFLAx5s1ze5i/WsvmLtXz2xVd43NOuwuv8/ludR9vblLORV/3vNEtMr3RxccHT05OIiAiGDh1KREQEnp6exuGXquZVxOKB3s/PD3d393J7zkLpGvfizvj9haviW7c4tHMb7bt2w8Wt9Em/UzMNbm3aEXPgR7r5/vGS28n9u1Cp7OjgLVPs6pr2HTrywbLV5dJfe2Us/f/hx+Anh+PesjW9+/Zj9Yowog/9H23bdzCWiz50gPoNGnBPu3sB8On5CPXq1yf60M/0eqTvH+UO/gxAR89OiPKqu4DZggULiIqK4saNG4wZMwYnJye2b9/OW2+9RXBwMJ988glqtZrQ0FDjOVXNq4jFA727uzsbN25Eo9GUy+vTp4+lb18nxR7aC0DSpfMAnD8ZTWO1I43VTtxzvxcACXEnycnK4GZG6RP1q/HnqN+wEQCde/Q1Xuu/2zbg1FxDk6YuZN5I4VBkOBk3kpkwv+yDogHPvsz60DcJ//Q9ujzcD33CRfZ+s56eg/8pc+jroCZN1Hg/1M1knsZNa8xr2+5eBvkNZc2KpRhKSrj3Pk+ORR9i+7ff8MLYCdjb2wPg6OTEcwHj+Hz1Cho3dsBb151zZ8+wbtVyBj7xJC1bta6xtlmT6j7nmjVrFrNmzSqX3q5dO7766iuT51Q1ryIWD/QDBgzg2rVrJgN9//7lX9O/G2x6/60yX3+38gMA7rm/K+PeKp39sHvLGhLiYoxlDkeGcziydG2hhVv2GtMLC/LYtWklWempNGzsQIeu3Xn233NxauZa5h4dH+zBs/+ey56t6zi+dycOjk3pM+x5+g6XV9+t3etvzqFZc1e+2bKR9LRU3LTuTJoytdyyBgHjJmJvb0/415vZ/MVaXJo1Z9Tzo3nxJXkz2hxbGdFSGEyNqdRhW2P0tV0FUcc87CG/kQjTtI71q3X+ySumpx57tbauCQwyvVIIIcywlRnKEuiFEMKMu3qZYiGEuBvYykuHEuiFEMIMa9wf1hQJ9EIIYYbSRiK9BHohhDDDRkZuJNALIYQ5ssOUEELYOAn0Qghh42xkiF4CvRBCmCMPY4UQwsbZSJyXQC+EEObIC1NCCGHjZAkEIYSwcTYS5yXQCyGEOTK9UgghbJytbDwigV4IIcyQHr0QQtg4G4nzEuiFEMIcmXUjhBA2TubRCyGEjbOVN2MVBoPBUNuVEEIIYTk2MnlICCGEORLohRDCxkmgF0IIGyeBXgghbJwEeiGEsHES6IUQwsZJoBdCCBsngV4IIWycBHohhLBxEuitUEJCAiNHjmTgwIGMHDmSy5cv13aVRC0LDQ2lX79+dOzYkfPnz9d2dUQdI4HeCs2ZMwd/f38iIyPx9/cnJCSktqskapmvry8bNmzA3d29tqsi6iAJ9FYmNTWVuLg4/Pz8APDz8yMuLo60tLRarpmoTTqdDq1WW9vVEHWUBHoro9fr0Wg0qFQqAFQqFa6uruj1+lqumRCirpJAL4QQNk4CvZXRarUkJydTXFwMQHFxMSkpKfJruxDCLAn0VsbFxQVPT08iIiIAiIiIwNPTE2dn51qumRCirpKNR6xQfHw8wcHBZGVloVarCQ0NpW3btrVdLVGLFixYQFRUFDdu3KBp06Y4OTmxffv22q6WqCMk0AshhI2ToRshhLBxEuiFEMLGSaAXQggbJ4FeCCFsnAR6IYSwcRLohdUJDg7mgw8+AODo0aMMHDiwRu7bsWNHEhMTa+ReQtxJEuiFxfTr148uXbrg7e1Nr169CA4OJicn547eQ6fTERkZedty33zzDc8+++wdvbcQ1kICvbCo5cuXc+LECbZt20ZsbCzLli0rk3/r1q1aqpkQdw8J9KJGaDQaHnnkES5cuEDHjh3ZsGEDAwYMYMCAAQD89NNPDB06FJ1Ox6hRo/jll1+M58bFxTFs2DC8vb2ZMmUKBQUFxrzDhw/z6KOPGr/W6/UEBgbSo0cPfHx8mDdvHvHx8cyZM4eTJ0/i7e2NTqcDoLCwkNDQUPr27UuvXr0ICQkhPz/feK2VK1fSu3dvevfuzdatWy39EQlhMRLoRY3Q6/Xs27cPT09PAH788Ue2bNnCDz/8QFxcHDNmzGDevHkcPnyYkSNHMmnSJAoLCyksLGTy5MkMHTqU6OhoBg0aRFRUlMl7FBcXM2HCBFq0aMGePXvYt28fgwcPpl27dsydOxcvLy9OnDjB0aNHAViyZAkJCQmEh4cTFRVFSkoKS5cuBWDfvn2sXr2a1atXExUVxcGDB2vmgxLCAiTQC4uaPHkyOp0Of39/unXrxsSJEwEYP348Tk5ONGzYkM2bNzNy5Ei6du2KSqVi2LBh1KtXj5MnTxITE0NRUREBAQHUq1ePQYMG8cADD5i816lTp0hJSWHatGnY29vToEEDY+/9rwwGA1u2bGHGjBk4OTnh4ODAhAkTjOvD7Nixg+HDh9OhQwfs7e0JDAy0zAckRA2wq+0KCNu2dOlSevXqVS79z8sqJyUlER4ezhdffGFMKyoqIiUlBYVCgUajQaFQGPNatGhh8l56vZ4WLVpgZ3f7b+u0tDTy8vIYPny4Mc1gMFBSUgJASkoKnTt3NubJFn3CmkmgF7Xiz4Fbq9UyceJEXnnllXLloqOjSU5OxmAwGM9JSkqiVatW5cpqtVr0ej23bt0qF+z/fD+Apk2b0rBhQ7Zv345Goyl3rb/u2pWUlPT3GihEHSJDN6LWjRgxgi+//JKYmBgMBgO5ubns3buX7OxsvLy8sLOz4/PPP6eoqIioqChOnz5t8jpdunShefPmvPfee+Tm5lJQUMCxY8eA0nX8k5OTKSwsBECpVDJixAjefvttUlNTAUhOTmb//v0ADBo0iG3btnHx4kXy8vIICwurgU9CCMuQQC9q3QMPPMD8+fOZN28e3bp1Y8CAAXzzzTcA1K9fn48//pht27bRvXt3fvjhB/r372/yOiqViuXLl5OYmMhjjz3Go48+yo4dOwDo0aMH7du3p3fv3vj4+AAwdepU2rRpwzPPPMODDz7I6NGjSUhIAKBPnz4EBAQQEBBA//796dGjRw18EkJYhqxHL4QQNk569EIIYeMk0AshhI2TQC+EEDZOAr0QQtg4CfRCCGHjJNALIYSNk0AvhBA2TgK9EELYOAn0Qghh4/4fvTN7DCw9wesAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x144 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGeq0LJWlLTt",
        "outputId": "17a181b6-bdea-447a-cdc8-2cbb752abe8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "importances = model.feature_importances_\n",
        "std = np.std([model.feature_importances_ for tree in model.estimators_],\n",
        "             axis=0)\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Print the feature ranking\n",
        "print(\"Feature ranking:\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-0ddf8b4a38a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimportances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m std = np.std([model.feature_importances_ for tree in model.estimators_],\n\u001b[0m\u001b[1;32m      3\u001b[0m              axis=0)\n\u001b[1;32m      4\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-0ddf8b4a38a7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimportances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m std = np.std([model.feature_importances_ for tree in model.estimators_],\n\u001b[0m\u001b[1;32m      3\u001b[0m              axis=0)\n\u001b[1;32m      4\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfeature_importances_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1709\u001b[0m         relevant_feature_importances = [\n\u001b[1;32m   1710\u001b[0m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_feature_importances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1711\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelevant_trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1712\u001b[0m         ]\n\u001b[1;32m   1713\u001b[0m         avg_feature_importances = np.mean(relevant_feature_importances,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1709\u001b[0m         relevant_feature_importances = [\n\u001b[1;32m   1710\u001b[0m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_feature_importances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1711\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelevant_trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1712\u001b[0m         ]\n\u001b[1;32m   1713\u001b[0m         avg_feature_importances = np.mean(relevant_feature_importances,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxI7XA7Km8R8",
        "outputId": "24894e47-24a9-49fe-81a3-e53d1c714199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for f in range(X.shape[1]):\n",
        "    print(X_labels[f])\n",
        "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
        "    print('-------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X\n",
            "1. feature 0 (0.291662)\n",
            "-------------\n",
            "Y\n",
            "2. feature 1 (0.283947)\n",
            "-------------\n",
            "CALL DAY OF WEEK\n",
            "3. feature 3 (0.128915)\n",
            "-------------\n",
            "CALL HOUR\n",
            "4. feature 4 (0.111926)\n",
            "-------------\n",
            "CALL MONTH\n",
            "5. feature 2 (0.085545)\n",
            "-------------\n",
            "1 or 2 family dwelling \\ House \\ Residen\n",
            "6. feature 5 (0.020178)\n",
            "-------------\n",
            "Residential street, road or residential\n",
            "7. feature 7 (0.011327)\n",
            "-------------\n",
            "Multifamily dwellings \\ Apartments\n",
            "8. feature 6 (0.008503)\n",
            "-------------\n",
            "Street, other\n",
            "9. feature 17 (0.007082)\n",
            "-------------\n",
            "Residential, other\n",
            "10. feature 8 (0.005606)\n",
            "-------------\n",
            "Highway or divided highway\n",
            "11. feature 19 (0.005188)\n",
            "-------------\n",
            "Street or road in commercial area\n",
            "12. feature 13 (0.004469)\n",
            "-------------\n",
            "Vacant lot\n",
            "13. feature 18 (0.004178)\n",
            "-------------\n",
            "Church, mosque, synagogue, temple, chape\n",
            "14. feature 11 (0.003204)\n",
            "-------------\n",
            "Vehicle parking area\n",
            "15. feature 12 (0.003067)\n",
            "-------------\n",
            "Open land or field\n",
            "16. feature 26 (0.003066)\n",
            "-------------\n",
            "Parking garage, (detached residential ga\n",
            "17. feature 21 (0.003057)\n",
            "-------------\n",
            "24-hour care Nursing homes, 4 or more pe\n",
            "18. feature 22 (0.002573)\n",
            "-------------\n",
            "Manufacturing, processing\n",
            "19. feature 14 (0.002263)\n",
            "-------------\n",
            "Business office\n",
            "20. feature 10 (0.002187)\n",
            "-------------\n",
            "Mercantile, business, other\n",
            "21. feature 9 (0.002174)\n",
            "-------------\n",
            "Elementary school, including kindergarte\n",
            "22. feature 20 (0.001749)\n",
            "-------------\n",
            "Warehouse\n",
            "23. feature 16 (0.001415)\n",
            "-------------\n",
            "Convenience store\n",
            "24. feature 29 (0.001370)\n",
            "-------------\n",
            "Restaurant or cafeteria\n",
            "25. feature 28 (0.001233)\n",
            "-------------\n",
            "Motor vehicle or boat sales, services, r\n",
            "26. feature 31 (0.001057)\n",
            "-------------\n",
            "High school/junior high school/middle sc\n",
            "27. feature 15 (0.001021)\n",
            "-------------\n",
            "Service station, gas station\n",
            "28. feature 24 (0.000372)\n",
            "-------------\n",
            "Undetermined\n",
            "29. feature 32 (0.000360)\n",
            "-------------\n",
            "Schools, non-adult\n",
            "30. feature 30 (0.000318)\n",
            "-------------\n",
            "Outside or special property, other\n",
            "31. feature 25 (0.000285)\n",
            "-------------\n",
            "Hotel/motel, commercial\n",
            "32. feature 33 (0.000239)\n",
            "-------------\n",
            "Food and beverage sales, grocery store\n",
            "33. feature 23 (0.000234)\n",
            "-------------\n",
            "Bar or nightclub\n",
            "34. feature 27 (0.000228)\n",
            "-------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUGbWN-C_rXE"
      },
      "source": [
        "#Analysis\n",
        "\n",
        "###Results and Operationalizing\n",
        "While I was able to find a better-than-chance predictor with both the Random Forest Classifier and Gradient Boosting Clasifier - evident by the AUCs of .61 - the main takeaway from this research is that false alarms are highly difficult to predict. Especially when you take into account the high cost of a false positive - a predicted False Alarm when it's a real emergency - it is unlikely that a fire department would ever use my model to justify not sending a crew to investigate a call. I think that it is possible that a better model could be formed with more data, but unlikely. Still, the fire departments could use a model like mine to determine which trucks or firefighters should be sent to which locations, or perhaps to investigate where smoke alarms are too sensitive. \n",
        "\n",
        "###Possible Further Research\n",
        "It is possible that this model could be improved if we had a feature explaining how the call was made - was it a phone call, or an automatic call triggered by a smoke alarm, or a pulled fire alarm? Could transcripts of phone calls help as well? \n",
        "\n",
        "Additionally, I had a second question in the back of my mind throughout this process: Can we predict when a fire will result in injuries or fatalities? This may be useful for an ambulance service. I created a binary variable which was a 1 if there were any injuries or fatalities and a 0 if there was not. As in the original question, I tried to find a classification model to predict this label. Finding a model that did not predict everything as \"No injury/fatality\" was taking me too much time, so I decided to dive deeper into my original question instead of looing more into this. Still, it is an area that could be followed up in with more research. I also briefly considered if there were differences in the fire departments' response times based on time of day by working with histograms of time series data, but did not find anything significant. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6I9p2ca-_sUq"
      },
      "source": [
        "#Conclusion\n",
        "In this lab, I was able to utilize many of the skills I have honed over the course of this semester, including working with time series data, binarizing data, balancing a dataset, choosing the best model given a situation, and tuning hyperparameters. \n",
        "\n",
        "I learned that real world datasets are often not as predictable as some of the ones we have looked at in class, and how to communicate results when this is the case. \n",
        "\n",
        "Something I learned that I didn't expect to is how easy it is to convince myself that my models are good. For example, my best model only misses real emergencies .042% of the time. I could probably convince some people to use it if I harped on numbers like this. But it's important to realize that this is still 211 emergencies that go undetected out of 4,000 calls - given the context, I don't have an incredible model. I think this is an especially important lesson to learn right now, as scientists roll out more tests for COVID-19.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--ORsS8z_yt7"
      },
      "source": [
        "#Acknowledgments\n",
        "I did not receive any help on this project except from Dr. Allen. The only help I gave was to suggest to Kristin that she try the Gradient Boosting Classifier because she was also working with an imbalanced dataset and her best results were Random Forest, but she hadn't tried GBC yet. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSFfbD5OhIeD"
      },
      "source": [
        "#References\n",
        "Manipulating Data  \n",
        "https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.Timestamp.html  \n",
        "\n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html  \n",
        "\n",
        "https://www.datacamp.com/community/tutorials/joining-dataframes-pandas  \n",
        "\n",
        "https://thispointer.com/python-pandas-how-to-drop-rows-in-dataframe-by-conditions-on-column-values/  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Displaying Data  \n",
        "https://stackoverflow.com/questions/19233771/sklearn-plot-confusion-matrix-with-labels\n",
        "\n",
        "Choosing a Classifier  \n",
        "https://scikit-learn.org/stable/modules/naive_bayes.html  \n",
        "\n",
        "https://stackabuse.com/overview-of-classification-methods-in-python-with-scikit-learn/  \n",
        "\n",
        "https://scikit-learn.org/stable/modules/neural_networks_supervised.html  \n",
        "\n",
        "https://stackoverflow.com/questions/52763325/how-to-obtain-only-the-name-of-a-models-object-in-scikitlearn\n",
        "\n",
        "https://stackoverflow.com/questions/268272/getting-key-with-maximum-value-in-dictionary\n",
        "\n",
        "Dealing with Imbalanced Data  \n",
        "https://towardsdatascience.com/what-to-do-when-your-classification-dataset-is-imbalanced-6af031b12a36\n",
        "\n",
        "https://towardsdatascience.com/comparing-different-classification-machine-learning-models-for-an-imbalanced-dataset-fdae1af3677f\n",
        "\n",
        "\n",
        "Hyperparameter Tuning/Grid Search  \n",
        "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
        "\n"
      ]
    }
  ]
}